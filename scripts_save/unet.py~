from theano import tensor as T
import lasagne_dev as nn
# lasagne should be the latest (under development verison)
# sudo pip install --upgrade https://github.com/Theano/Theano/archive/master.zip
# sudo pip install --upgrade https://github.com/Lasagne/Lasagne/archive/master.zip
# sudo pip install lasagne Pillow

# input_var = your input image
# 4D: 1 - index of image (0,1,2,...,batch_size)
#     2 - channel (RGB: 3, BW: 1)
#     3 - actual image (Y)
#     4 - actual image (X)
# label_var = also 4D
#     1 - image IDs (0,1,2,3, ...,batch_size )
#     2 - 1
#     3 - label image (Y)
#     4 - label image (X)
# shape = gives shape of inputs (use this as a sanity check for expected image size)
#     [16, 1, 272, 272,]

# size = (116, 116)

def sorenson_dice(pred, target):
    # 2 is just a scaling factor
    # add a number at end (20) to avoid dividing by 0
    return -2*T.sum(pred*target)/T.sum(pred+target+0.0001)

def network(input_var, label_var, shape):
    layer = nn.layers.InputLayer(shape,input_var) #input layer (image size 116)
    
    #convolution layers (32 filters)
    #nonlinearality = nn.nonlinearities.rectify <-- ReLu
    layer = nn.layers.gabor_Conv2DLayer(layer, num_filters = 4,filter_size = 5,
                                  nonlinearity = nn.nonlinearities.rectify) #112
    
    # max pool layer (stride = 2)
    layer = nn.layers.MaxPool2DLayer(layer, pool_size = 2) #56 (half of previous layer)
    
    #convolution layers (64 filters)
    layer = nn.layers.gabor_Conv2DLayer(layer, num_filters = 8,filter_size = 5,
                                  nonlinearity = nn.nonlinearities.rectify) #52

    '''                                  
    # max pool layer
    layer = nn.layers.MaxPool2DLayer(layer, pool_size = 2) #26 (half of previous layer)
    
    #convolution layers (256 filters)
    layer = nn.layers.gabor_Conv2DLayer(layer, num_filters = 16,filter_size = 5,
                                  nonlinearity = nn.nonlinearities.rectify) #22
                                     
                                    
    #convolutional layers with 'full' pad
    layer = nn.layers.gabor_Conv2DLayer(layer, num_filters = 16,filter_size = 5,
                                  nonlinearity = nn.nonlinearities.rectify, pad = 'full') #26

    
    #upscale layer
    layer = nn.layers.Upscale2DLayer(layer, scale_factor = 2) #52
    '''
    #convolutional layers with 'full' pad
    layer = nn.layers.gabor_Conv2DLayer(layer, num_filters = 8,filter_size = 5,
                                  nonlinearity = nn.nonlinearities.rectify, pad = 'full') #56
                                  
    #upscale layer
    layer = nn.layers.Upscale2DLayer(layer, scale_factor = 2) #112
    
    #convolutional layers with 'full' pad
    
    layer = nn.layers.gabor_Conv2DLayer(layer, num_filters = 1,filter_size = 5,
                                  nonlinearity = nn.nonlinearities.sigmoid, pad = 'full') #116 


    # this gives the labels for the image that was fed into the nn
    # get_output can be used for any layer, not just final
    output = nn.layers.get_output(layer) # parameters will be updated - use for train
    output_det = nn.layers.get_output(layer, deterministic=True) # no backpropagation, params are fixed, use for testing
    loss = sorenson_dice(output, label_var) #for training loss
    test_loss = sorenson_dice(output_det, label_var) #for test loss
    test_acc = nn.objectives.binary_accuracy(output_det, label_var)

    return layer, loss, test_loss, test_acc, output_det
    
    
