{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano import tensor as T\n",
    "import lasagne_dev as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "from input_process import read_images\n",
    "import random\n",
    "import math\n",
    "import cmath\n",
    "from g_gradient import *\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = (116, 116)\n",
    "pkl_file = open('../fnames_collection_2', 'r')\n",
    "fnames = pkl_file.readline()\n",
    "fnames = fnames.split(' ')\n",
    "for i in range (0,len(fnames)):\n",
    "\tfnames[i] = str(fnames[i])\n",
    "\tfnames[i] = 'image' + fnames[i] + '.png'\n",
    "\n",
    "train_index = fnames[0:5]\n",
    "\n",
    "label_path = '../NewPNGlabeled/'\n",
    "ori_path = '../JpegOriginalImg/'\n",
    "train_input, train_label = read_images(label_path, ori_path, train_index, size)\n",
    "#test_input, test_label, shape = read_images(label_path, ori_path, test_index, size)\n",
    "\n",
    "input_var = train_input\n",
    "label_var = train_label\n",
    "shape = [5,1,116,116]\n",
    "layer = nn.layers.InputLayer(shape,input_var)\n",
    "layer = nn.layers.gabor_Conv2DLayer(layer, num_filters = 4,filter_size = 7,\n",
    "                              nonlinearity = nn.nonlinearities.sigmoid, pad = 'same') #116 \n",
    "layer = nn.layers.gabor_Conv2DLayer(layer, num_filters = 8,filter_size = 7,\n",
    "                              nonlinearity = nn.nonlinearities.sigmoid, pad = 'same')\n",
    "layer = nn.layers.Conv2DLayer(layer, num_filters = 1,filter_size = 7,\n",
    "                              nonlinearity = nn.nonlinearities.sigmoid, pad = 'same') #116 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = nn.layers.get_output(layer) # parameters will be updated - use for train\n",
    "#output_det = nn.layers.get_output(layer, deterministic=True) \n",
    "params = nn.layers.get_all_params(layer)\n",
    "gs = nn.layers.get_all_gs(layer)\n",
    "loss = -2*T.sum(output*label_var)/T.sum(output+label_var+0.0001)\n",
    "rand = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_updates_dev(loss, params, gs, rand, lr=0.001):\n",
    "    gs_gradients = []\n",
    "    gradients = nn.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    for w_index in range (0, 2):\n",
    "        # First Loop\n",
    "        # print(w_index)\n",
    "        \n",
    "        ws = params[w_index*2]\n",
    "        g_params = gs[w_index]\n",
    "        ws_gradients = gradients[w_index*2]\n",
    "\n",
    "        [num_filters, num_channels, filter_size, filter_size] = ws.get_value().shape\n",
    "        \n",
    "        position = int(math.floor(filter_size/2))\n",
    "        ws_grad = ws_gradients[:,:,position:position+1,position]\n",
    "\n",
    "        # select which parameter to update\n",
    "        #rand = random.randint(1,3)\n",
    "        # rand = 1\n",
    "        which_parameter = np.array([[1,0,0,0,0], [0,1,0,0,0], [0,0,1,0,0], [0,0,0,1,0],[0,0,0,0,1]][rand-1])\n",
    "        fns = [g_f, g_gamma, g_sigma, g_theta, g_psi]\n",
    "        fn = fns[rand-1]\n",
    "\n",
    "        # Second and third Loop\n",
    "        additions = []\n",
    "        for i in range (0, num_filters):\n",
    "            for j in range (0, num_channels):\n",
    "                g = g_params[i,j,:]\n",
    "                additions.append(fn(0,0,g))\n",
    "                #additions.append(calculate_gradient_for_g(fn,g,filter_size))\n",
    "                \n",
    "        additions = theano.tensor.stack(additions).reshape([num_filters,num_channels,-1])\n",
    "        gp_list = np.array([ws_grad, ws_grad, ws_grad, ws_grad, ws_grad])*which_parameter\n",
    "        gp = theano.tensor.concatenate(np.ndarray.tolist(gp_list), axis=2)\n",
    "        gs_gradient = []\n",
    "        for i in range(0,num_filters):\n",
    "            for j in range(0,num_channels):\n",
    "                gs_gradient.append(gp[i,j,:]*additions[i,j,0])\n",
    "\n",
    "        gs_gradients.append(theano.tensor.concatenate(gs_gradient, axis=0).reshape([num_filters,num_channels,-1]))\n",
    "    gs_updates = nn.updates.adam_dev(gs_gradients, gs, learning_rate=lr)\n",
    "    return gs_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_updates = g_updates_dev(loss, params, gs, rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = OrderedDict()\n",
    "lr = theano.shared(nn.utils.floatX(1e-4)) # learning rate\n",
    "updates_old = nn.updates.adam(loss, params, learning_rate=lr)\n",
    "for i in range (0,len(gs)):\n",
    "    print(i)\n",
    "    gs_new = gs_updates[gs[i]]\n",
    "    #gs_new.dtype = np.float32\n",
    "    ws = params[i*2]\n",
    "    [num_filters, num_channels, filter_size, filter_size] = ws.get_value().shape\n",
    "    W = gabor_weight_update([num_filters, num_channels, filter_size, filter_size], gs_new)\n",
    "    #updates[ws] = theano.shared(W)\n",
    "    updates[ws] = W\n",
    "    updates[params[i*2+1]] = updates_old[params[i*2+1]]\n",
    "    updates[gs[i]] = gs_new\n",
    "\n",
    "for j in range (2*len(gs),len(params)):\n",
    "    updates[params[j]] = updates_old[params[j]]\n",
    "\n",
    "print(gs_updates[gs[0]].dtype)\n",
    "gs_new = gs_updates[gs[i]]\n",
    "ws = params[0*2]\n",
    "[num_filters, num_channels, filter_size, filter_size] = ws.get_value().shape\n",
    "W = gabor_weight_update([num_filters, num_channels, filter_size, filter_size], gs_new)\n",
    "print(W.dtype)\n",
    "\n",
    "print(updates[params[0]].dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_gradients = []\n",
    "gradients = nn.updates.get_or_compute_grads(loss, params)\n",
    "\n",
    "for w_index in range (0, 2):\n",
    "    # First Loop\n",
    "    # print(w_index)\n",
    "\n",
    "    ws = params[w_index*2]\n",
    "    g_params = gs[w_index]\n",
    "    ws_gradients = gradients[w_index*2]\n",
    "\n",
    "    [num_filters, num_channels, filter_size, filter_size] = ws.get_value().shape\n",
    "\n",
    "    position = int(math.floor(filter_size/2))\n",
    "    ws_grad = ws_gradients[:,:,position:position+1,position]\n",
    "\n",
    "    # select which parameter to update\n",
    "    #rand = random.randint(1,3)\n",
    "    # rand = 1\n",
    "    which_parameter = np.array([[1,0,0,0,0], [0,1,0,0,0], [0,0,1,0,0], [0,0,0,1,0],[0,0,0,0,1]][rand-1])\n",
    "    fns = [g_f, g_gamma, g_sigma, g_theta, g_psi]\n",
    "    fn = fns[rand-1]\n",
    "\n",
    "    # Second and third Loop\n",
    "    additions = []\n",
    "    for i in range (0, num_filters):\n",
    "        for j in range (0, num_channels):\n",
    "            g = g_params[i,j,:]\n",
    "            additions.append(fn(0,0,g))\n",
    "            #additions.append(calculate_gradient_for_g(fn,g,filter_size))\n",
    "\n",
    "    additions = theano.tensor.stack(additions).reshape([num_filters,num_channels,-1])\n",
    "    gp_list = np.array([ws_grad, ws_grad, ws_grad, ws_grad, ws_grad])*which_parameter\n",
    "    gp = theano.tensor.concatenate(np.ndarray.tolist(gp_list), axis=2)\n",
    "    \n",
    "    gs_gradient = []\n",
    "    for i in range(0,num_filters):\n",
    "        for j in range(0,num_channels):\n",
    "            gs_gradient.append(gp[i,j,:]*additions[i,j,0])\n",
    "\n",
    "    gs_gradients.append(theano.tensor.concatenate(gs_gradient, axis=0).reshape([num_filters,num_channels,-1]))\n",
    "gs_updates = nn.updates.adam_dev(gs_gradients, gs, learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_updates[gs[0]].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = nn.updates.get_or_compute_grads(loss, params)\n",
    "\n",
    "w_index=0\n",
    "ws = params[w_index*2]\n",
    "g_params = gs[w_index]\n",
    "ws_gradients = gradients[w_index*2]\n",
    "\n",
    "[num_filters, num_channels, filter_size, filter_size] = ws.get_value().shape\n",
    "\n",
    "position = int(math.floor(filter_size/2))\n",
    "ws_grad = ws_gradients[:,:,position:position+1,position]\n",
    "\n",
    "# select which parameter to update\n",
    "#rand = random.randint(1,3)\n",
    "# rand = 1\n",
    "which_parameter = np.array([[1,0,0,0,0], [0,1,0,0,0], [0,0,1,0,0], [0,0,0,1,0],[0,0,0,0,1]][rand-1])\n",
    "fns = [g_f, g_gamma, g_sigma, g_theta, g_psi]\n",
    "fn = fns[rand-1]\n",
    "\n",
    "# Second and third Loop\n",
    "additions = []\n",
    "for i in range (0, num_filters):\n",
    "    for j in range (0, num_channels):\n",
    "        g = g_params[i,j,:]\n",
    "        additions.append(fn(0,0,g))\n",
    "        #additions.append(calculate_gradient_for_g(fn,g,filter_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addition = theano.tensor.stack(additions).reshape([4,1,-1])\n",
    "addition.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ws_grad.eval())\n",
    "gp_list = np.array([ws_grad, ws_grad, ws_grad, ws_grad, ws_grad])*which_parameter\n",
    "gp = theano.tensor.concatenate(np.ndarray.tolist(gp_list), axis=2)\n",
    "gs_gradient = []\n",
    "for i in range(0,4):\n",
    "    for j in range(0,1):\n",
    "        gs_gradient.append(gp[i,j,:]*addition[i,j,0])\n",
    "#print(gp_list[0].shape.eval(),x.shape.eval())\n",
    "print(gp.eval(),addition.eval())\n",
    "#y = [x[0,0,:]*additions[0],x[1,0,:]*additions[1],x[2,0,:]*additions[2],x[3,0,:]*additions[3]]\n",
    "theano.tensor.concatenate(gs_gradient, axis=0).reshape([4,1,-1]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addition=theano.tensor.stack(additions).reshape([4,1,-1])\n",
    "y = []\n",
    "\n",
    "z = theano.tensor.concatenate(y)\n",
    "print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var = train_input\n",
    "label_var = train_label\n",
    "shape = [5,1,116,116]\n",
    "layer = nn.layers.InputLayer(shape,input_var)\n",
    "layer = nn.layers.gabor_Conv2DLayer(layer, num_filters = 4,filter_size = 3,\n",
    "                              nonlinearity = nn.nonlinearities.sigmoid, pad = 'same') #116 \n",
    "layer = nn.layers.gabor_Conv2DLayer(layer, num_filters = 1,filter_size = 3,\n",
    "                               nonlinearity = nn.nonlinearities.sigmoid, pad = 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = nn.layers.get_all_params(layer)\n",
    "params[0].shape.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = nn.layers.get_output(layer) # parameters will be updated - use for train\n",
    "#output_det = nn.layers.get_output(layer, deterministic=True) \n",
    "\n",
    "params = nn.layers.get_all_params(layer)\n",
    "gs = nn.layers.get_all_gs(layer)\n",
    "loss = -2*T.sum(output*label_var)/T.sum(output+label_var+0.0001)\n",
    "#print (loss.eval())\n",
    "\n",
    "lr = 1 # learning rate\n",
    "#updates = nn.updates.sgd(loss, params, learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_updates = g_updates(loss, params, gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gs_updates[gs[0]].eval()\n",
    "value = [gs_updates[gs[i]].eval() for i in range (0,len(gs))]\n",
    "#gs_updates[gs[0]].get_value()\n",
    "#updates = nn.updates.sgd(loss, params, learning_rate=lr)\n",
    "#value[0].eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = theano.shared(0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nn.layers.set_all_gs_values(layer, value)\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "updates = OrderedDict()\n",
    "updates_old = nn.updates.adam(loss, params, learning_rate=lr)\n",
    "for i in range (0,len(value)):\n",
    "    gs = value[i]\n",
    "    ws = params[i*2]\n",
    "    [num_filters, num_channels, filter_size, filter_size] = np.ndarray.tolist(ws.shape.eval())\n",
    "    W = nn.layers.gabor.gabor_filter_initiation([num_filters, num_channels, filter_size, filter_size], gs)\n",
    "    #updates[ws] = theano.shared(W)\n",
    "    updates[ws] = W\n",
    "    updates[params[i*2+1]] = updates_old[params[i*2+1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updates[params[0]].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updates_old = nn.updates.adm(loss, params, learning_rate=lr)\n",
    "updates_old[params[0]].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_gradients = np.array([], dtype=np.float32).reshape(1,-1)\n",
    "g_gradient = np.array([0,0,0,0,0.11]).reshape(1,-1)\n",
    "g_gradients = np.concatenate((g_gradients,g_gradient),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def get_g(layer):\n",
    "    if hasattr(layer, 'g'):\n",
    "        result = layer.g\n",
    "    else:\n",
    "        result = []\n",
    "    result = nn.utils.collect_shared_vars(result)\n",
    "    return result\n",
    "    \n",
    "layers = nn.layers.get_all_layers(layer)\n",
    "\n",
    "params = chain.from_iterable(get_g(l) for l in layers)\n",
    "params = nn.utils.unique(params)\n",
    "value = [g.get_value() for g in params]\n",
    "value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updates[params[0]].eval()\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gabor_filter(x,y,params):\n",
    "    f,gamma,sigma,theta,psi = params\n",
    "    xt = x*math.cos(theta) + y*math.sin(theta)\n",
    "    yt = -x*math.sin(theta) + y*math.cos(theta)\n",
    "    z1 = -(xt**2 + (gamma*yt)**2)/(2*sigma**2)\n",
    "    z2 = 1j*2*math.pi*f*xt+psi\n",
    "    value = f**2/(math.pi*gamma)*math.exp(z1)*cmath.exp(z2)\n",
    "    return value\n",
    "\n",
    "def g_theta(x,y,params):\n",
    "    f,gamma,sigma,theta,psi = params\n",
    "    value = gabor_filter(x,y,params)\n",
    "    return ((yt*xt/sigma**2)*(gamma**2-1)+1j*2*math.pi*f*yt)*value\n",
    "\n",
    "def g_f(x,y,params):\n",
    "    f,gamma,sigma,theta,psi = params\n",
    "    value = gabor_filter(x,y,params)  \n",
    "    return (2/f + 1j*2*math.pi*xt)*value\n",
    "\n",
    "def g_gamma(x,y,params):\n",
    "    f,gamma,sigma,theta,psi = params\n",
    "    value = gabor_filter(x,y,params)  \n",
    "    return -(yt**2*gamma/sigma**2+1/gamma)*value\n",
    "\n",
    "def g_theta(x,y,params):\n",
    "    f,gamma,sigma,theta,psi = params\n",
    "    value = gabor_filter(x,y,params)  \n",
    "    return ((xt**2 + gamma**2*yt**2)/sigma**3)*value\n",
    "\n",
    "def g_psi(x,y,params):\n",
    "    f,gamma,sigma,theta,psi = params\n",
    "    value = gabor_filter(x,y,params)  \n",
    "    return value\n",
    "\n",
    "\n",
    "def gabor_filter_update(size, params, f):\n",
    "    bond = math.floor(size/2)\n",
    "    x_range = np.linspace(-bond, bond, size)\n",
    "    y_range = np.linspace(-bond, bond, size)\n",
    "\n",
    "    [x_range,y_range] = list(map(lambda x:x.reshape(1,-1),np.meshgrid(x_range,y_range)))\n",
    "    gfilter = []\n",
    "    updates = []\n",
    "    for (x,y) in zip(np.ndarray.tolist(x_range)[0], np.ndarray.tolist(y_range)[0]):        \n",
    "        update = f(x,y,params)\n",
    "        updates.append(update.real)\n",
    "    updates = np.array(updates, dtype=np.float32).reshape(size,-1)\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = nn.layers.get_all_params(layer)\n",
    "gradients = nn.updates.get_or_compute_grads(loss, params)\n",
    "learning_rate = 1\n",
    "\n",
    "# First Loop\n",
    "ws_update = updates[params[0]]\n",
    "g_params = gs[0]\n",
    "ws = params[0]\n",
    "ws_gradients = gradients[0]\n",
    "#print(w_update, g_params)\n",
    "\n",
    "# Second and third Loop\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "g = g_params[i,j,:]\n",
    "w_update = ws_update[i,j,:,:]\n",
    "w = ws[i,j,:,:]\n",
    "filter_size = w.shape.eval()[0]\n",
    "w_gradient = ws_gradients[i,j,:]\n",
    "# sgd: calculate gradient from updates\n",
    "#gradient = (w - w_update)/learning_rate\n",
    "\n",
    "\n",
    "update_try = gabor_filter_update(filter_size, g.eval(), g_psi)\n",
    "\n",
    "a = (update_try*w_gradient).sum()\n",
    "psi_gradient = a/9\n",
    "\n",
    "psi_gradient.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradients = nn.updates.get_or_compute_grads(loss, params)\n",
    "print((gradients[0].eval())[0,0,:], '\\n')\n",
    "gradient = (w - w_update)/learning_rate\n",
    "print(gradient.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(update_try, '\\n', gradient)\n",
    "#print(update_try*gradient)\n",
    "#sum(sum(update_try*gradient))/filter_size**2\n",
    "from collections import OrderedDict\n",
    "gradient = nn.updates.get_or_compute_grads(loss, params)\n",
    "a = OrderedDict()\n",
    "for param, grad in zip(params, gradient):\n",
    "    a[param] = param - learning_rate * grad\n",
    "\n",
    "layer.g.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "def adam_dev(gradient, params, learning_rate=0.001, beta1=0.9,\n",
    "         beta2=0.999, epsilon=1e-8):\n",
    "    all_grads = gradient\n",
    "    t_prev = theano.shared(nn.utils.floatX(0.))\n",
    "    updates = OrderedDict()\n",
    "\n",
    "    # Using theano constant to prevent upcasting of float32\n",
    "    one = T.constant(1)\n",
    "\n",
    "    t = t_prev + 1\n",
    "    a_t = learning_rate*T.sqrt(one-beta2**t)/(one-beta1**t)\n",
    "\n",
    "    for param, g_t in zip(params, all_grads):\n",
    "        value = param.get_value(borrow=True)\n",
    "        m_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "        v_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "\n",
    "        m_t = beta1*m_prev + (one-beta1)*g_t\n",
    "        v_t = beta2*v_prev + (one-beta2)*g_t**2\n",
    "        step = a_t*m_t/(T.sqrt(v_t) + epsilon)\n",
    "\n",
    "        updates[m_prev] = m_t\n",
    "        updates[v_prev] = v_t\n",
    "        updates[param] = param - step\n",
    "\n",
    "    updates[t_prev] = t\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psi_gradient.eval()\n",
    "g_gradient = np.array([0,0,0,0,psi_gradient.eval()])\n",
    "g_gradient = theano.shared(nn.utils.floatX(g_gradient))\n",
    "\n",
    "g_updates = adam_dev([g_gradient], [gs[0]])\n",
    "print(g_updates[gs[0]].eval(),'\\n')\n",
    "print(gs[0].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = nn.updates.get_or_compute_grads(loss, params)\n",
    "x[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[num_filters, num_channels, size, size] = w_update.shape\n",
    "for i in range (0, num_filters):\n",
    "    for j in range (0, num_channels):\n",
    "        g_params = gs[i,j,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_1 = np.random.normal(0, 0.01, (3, 3))\n",
    "w_2 = np.random.normal(0, 0.02, (3, 3))\n",
    "a_1 = w_1.reshape(1,-1)\n",
    "a_2 = w_2.reshape(1,-1)\n",
    "ve = np.concatenate((a_1,a_2),axis=1)\n",
    "w_init = ve.reshape(2,1,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl_file = open('/Users/apple/Documents/Lab_Winter/GDCNN/scripts/params_epoch_400', 'rb')\n",
    "params = pickle.load(pkl_file)\n",
    "params[4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = np.ones([3,3])\n",
    "w1 = w1.reshape(-1,3,3)\n",
    "w2 = np.ones([3,3])*2\n",
    "w2 = w2.reshape(-1,3,3)\n",
    "W_filter1 = np.concatenate((w1,w2),axis=0)\n",
    "\n",
    "w1 = np.ones([3,3])\n",
    "w1 = w1.reshape(-1,3,3)\n",
    "w2 = np.ones([3,3])*2\n",
    "w2 = w2.reshape(-1,3,3)\n",
    "W_filter2 = np.concatenate((w1,w2),axis=0)\n",
    "\n",
    "w1 = np.ones([3,3])\n",
    "w1 = w1.reshape(-1,3,3)\n",
    "w2 = np.ones([3,3])*2\n",
    "w2 = w2.reshape(-1,3,3)\n",
    "W_filter3 = np.concatenate((w1,w2),axis=0)\n",
    "\n",
    "Ws = np.concatenate((W_filter1.reshape(-1,2,3,3),W_filter2.reshape(-1,2,3,3),W_filter3.reshape(-1,2,3,3)),axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we want to initial weight of [2,2,3,3]\n",
    "shape = [2,2,3,3]\n",
    "[NumChannel,NumFilter,size,size] = shape\n",
    "\n",
    "Ws = np.array([]).reshape(1,-1)\n",
    "for i in range (0,NumFilter*NumFilter):\n",
    "    w = np.ones([3,3]).reshape(1,-1) # np.ones([3,3]) can be replaced by other functions\n",
    "    Ws = np.concatenate((Ws,w),axis=1)\n",
    "Ws = Ws.reshape(2,2,3,3)\n",
    "Ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = [2,2,3,3]\n",
    "[NumChannel,NumFilter,size,size] = shape\n",
    "NumChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano import pp\n",
    "x = T.dscalar('x')\n",
    "y = T.dscalar('y')\n",
    "z = x ** 2 + y ** 2\n",
    "gz = T.grad(z,x)\n",
    "f = theano.function([x,y],gz)\n",
    "pp(f.maker.fgraph.outputs[0])\n",
    "\n",
    "#f = theano.function([x,y],gz)\n",
    "#pp(f.maker.fgraph.outputs[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nx, ny = (3, 2)\n",
    "x = np.linspace(-1, 1, 3)\n",
    "y = np.linspace(-1, 1, 3)\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "xv.reshape(1,-1), yv.reshape(1,-1)\n",
    "for i in x:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 3)\n",
    "y = np.linspace(-1, 1, 3)\n",
    "[x,y] = list(map(lambda x:x.reshape(1,-1),np.meshgrid(x,y)))\n",
    "print(math.floor(3/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = random.uniform(0.0001,2)\n",
    "gamma = random.uniform(0.0001,1)\n",
    "sigma = random.uniform(0.0001,2)\n",
    "theta = random.uniform(0,2*math.pi)    \n",
    "psi = random.uniform(0.0001,2)\n",
    "    \n",
    "bond = math.floor(size/2)\n",
    "x_range = np.linspace(-bond, bond, size)\n",
    "y_range = np.linspace(-bond, bond, size)\n",
    "\n",
    "[x_range,y_range] = list(map(lambda x:x.reshape(1,-1),np.meshgrid(x_range,y_range)))\n",
    "gfilter = []\n",
    "for (x,y) in zip(np.ndarray.tolist(x_range)[0], np.ndarray.tolist(y_range)[0]):\n",
    "    xt = x*math.cos(theta) + y*math.sin(theta)\n",
    "    yt = -x*math.sin(theta) + y*math.cos(theta)\n",
    "    z1 = -(xt**2 + (gamma*yt)**2)/(2*sigma**2)\n",
    "    z2 = 1j*2*math.pi*f*xt+psi\n",
    "    value = f**2/(math.pi*gamma)*math.exp(z1)*cmath.exp(z2)\n",
    "    gfilter.append(value.real)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cmath\n",
    "cmath.exp(2j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from theano import tensor\n",
    "import theano\n",
    "from theano import pp\n",
    "\n",
    "math.exp(0)\n",
    "f = T.fscalar('f')\n",
    "gamma = T.fscalar('gamma')\n",
    "sigma = T.fscalar('sigma')\n",
    "theta = T.fscalar('theta')\n",
    "psi = T.fscalar('psi')\n",
    "x = T.fscalar('x')\n",
    "y = T.fscalar('y')\n",
    "\n",
    "xt = x*T.cos(theta) + y*T.sin(theta)\n",
    "yt = -x*T.sin(theta) + y*T.cos(theta)\n",
    "z1 = -(xt**2 + (gamma*yt)**2)/(2*sigma**2)\n",
    "z2 = 1j*2*math.pi*f*xt+psi\n",
    "value = f**2/(math.pi*gamma)*math.exp(z1)*cmath.exp(z2)\n",
    "\n",
    "gz = T.grad(value,theta)\n",
    "f = theano.function([x,y,f,gamma,sigma,theta,psi],gz)\n",
    "pp(f.maker.fgraph.outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano import tensor\n",
    "import theano\n",
    "from theano import pp\n",
    "xt = x*tensor.cos(2*theta)\n",
    "gz = theano.grad(xt,x)\n",
    "#f = theano.function([x,theta],gz)\n",
    "#pp(f.maker.fgraph.outputs[0])\n",
    "gz_new = gz*1.5\n",
    "f = theano.function([x,theta],gz_new)\n",
    "f(1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "math.cos(2)*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.ndarray.tolist(np.random.randint(0,10,5))\n",
    "index[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]\n",
    "random.shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "a.reshape(1,-1)\n",
    "b = np.array([6,7,8,9])\n",
    "Ws = np.concatenate((a,b),axis=0)\n",
    "Ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "Ws = np.concatenate((Ws,a),axis=0)\n",
    "Ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gs[0]\n",
    "params = g[0,0]\n",
    "params.shape.get_value()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
